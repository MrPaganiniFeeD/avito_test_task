{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DONE] ds1: copied=1863, missing_label=0\n",
      "[DONE] ds2: copied=1061, missing_label=0\n",
      "[DONE] ds3: copied=180, missing_label=0\n",
      "[DONE] ds4: copied=2094, missing_label=0\n",
      "=== SUMMARY ===\n",
      "ds1 {'copied': 1863, 'missing_label': 0, 'no_split': 0}\n",
      "ds2 {'copied': 1061, 'missing_label': 0, 'no_split': 0}\n",
      "ds3 {'copied': 180, 'missing_label': 0, 'no_split': 0}\n",
      "ds4 {'copied': 2094, 'missing_label': 0, 'no_split': 0}\n",
      "Combined folder ready at: data\\combined\n"
     ]
    }
   ],
   "source": [
    "# merge_datasets_specific.py\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "# Поменяй root на корень, где лежит папка data\n",
    "root = Path(\"data\")   # <-- у тебя data/\n",
    "datasets = [\n",
    "    root / \"all-books\",\n",
    "    root / \"book\",\n",
    "    root / \"Book_200img\",\n",
    "    root / \"book_detection2\",\n",
    "]\n",
    "\n",
    "out = root / \"combined\"\n",
    "imgs_out = out / \"images\"\n",
    "lbls_out = out / \"labels\"\n",
    "\n",
    "for split in [\"train\", \"val\"]:\n",
    "    (imgs_out / split).mkdir(parents=True, exist_ok=True)\n",
    "    (lbls_out / split).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "IMG_EXTS = {\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tif\", \".tiff\", \".webp\"}\n",
    "\n",
    "def copy_pair(src_img, src_lbl, dest_img, dest_lbl):\n",
    "    dest_img.parent.mkdir(parents=True, exist_ok=True)\n",
    "    dest_lbl.parent.mkdir(parents=True, exist_ok=True)\n",
    "    shutil.copy2(src_img, dest_img)\n",
    "    shutil.copy2(src_lbl, dest_lbl)\n",
    "\n",
    "summary = {}\n",
    "for i, ds in enumerate(datasets, start=1):\n",
    "    prefix = f\"ds{i}\"\n",
    "    summary[prefix] = {\"copied\":0, \"missing_label\":0, \"no_split\":0}\n",
    "    if not ds.exists():\n",
    "        print(f\"[WARN] dataset not found: {ds} — skipping\")\n",
    "        continue\n",
    "\n",
    "    # ожидаем структуру ds/{train,val,test}/images labels\n",
    "    for split in [\"train\",\"val\"]:\n",
    "        imgs_dir = ds / split / \"images\"\n",
    "        lbls_dir = ds / split / \"labels\"\n",
    "        if not imgs_dir.exists():\n",
    "            # иногда папки называются images в корне ds/images/train - но ты сказал структура именно как в примере\n",
    "            print(f\"[INFO] {prefix}: no {split}/images — пропускаю {split}\")\n",
    "            summary[prefix][\"no_split\"] += 1\n",
    "            continue\n",
    "        img_files = [p for p in imgs_dir.iterdir() if p.suffix.lower() in IMG_EXTS]\n",
    "        for img in img_files:\n",
    "            lbl = lbls_dir / f\"{img.stem}.txt\"\n",
    "            if not lbl.exists():\n",
    "                summary[prefix][\"missing_label\"] += 1\n",
    "                # пропускаем такие изображения\n",
    "                continue\n",
    "            new_img = imgs_out / split / f\"{prefix}_{img.name}\"\n",
    "            new_lbl = lbls_out / split / f\"{prefix}_{lbl.name}\"\n",
    "            copy_pair(img, lbl, new_img, new_lbl)\n",
    "            summary[prefix][\"copied\"] += 1\n",
    "\n",
    "    print(f\"[DONE] {prefix}: copied={summary[prefix]['copied']}, missing_label={summary[prefix]['missing_label']}\")\n",
    "\n",
    "print(\"=== SUMMARY ===\")\n",
    "for k,v in summary.items():\n",
    "    print(k, v)\n",
    "print(\"Combined folder ready at:\", out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Found names in data\\all-books\\data.yaml\n",
      "Wrote data\\combined\\data.yaml\n"
     ]
    }
   ],
   "source": [
    "# make_combined_data_yaml.py\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "\n",
    "root = Path(\"data\")\n",
    "combined = root / \"combined\"\n",
    "data_yaml = combined / \"data.yaml\"\n",
    "\n",
    "# Попробуем найти names в исходных data.yaml (первый найденный)\n",
    "candidates = list(root.rglob(\"data.yaml\"))\n",
    "names = None\n",
    "for p in candidates:\n",
    "    try:\n",
    "        d = yaml.safe_load(p.read_text())\n",
    "        if isinstance(d, dict) and 'names' in d:\n",
    "            names = d['names']\n",
    "            print(f\"[INFO] Found names in {p}\")\n",
    "            break\n",
    "    except Exception:\n",
    "        continue\n",
    "\n",
    "# Если names — dict (как 0: 'class'), преобразуем в список по индексам\n",
    "if isinstance(names, dict):\n",
    "    # сортируем по ключу\n",
    "    items = sorted(names.items(), key=lambda x: int(x[0]))\n",
    "    names = [v for k,v in items]\n",
    "\n",
    "if names is None:\n",
    "    names = []  # оставим пустым, ты должен заполнить вручную ниже\n",
    "\n",
    "data = {\n",
    "    'train': str((combined / \"images\" / \"train\").resolve()),\n",
    "    'val': str((combined / \"images\" / \"val\").resolve()),\n",
    "    'names': names\n",
    "}\n",
    "\n",
    "data_yaml.parent.mkdir(parents=True, exist_ok=True)\n",
    "data_yaml.write_text(yaml.safe_dump(data, sort_keys=False, allow_unicode=True))\n",
    "print(\"Wrote\", data_yaml)\n",
    "if not names:\n",
    "    print(\"WARNING: 'names' is empty — открой data/combined/data.yaml и укажи список классов (names).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ultralytics\n",
      "  Downloading ultralytics-8.3.202-py3-none-any.whl.metadata (37 kB)\n",
      "Collecting numpy>=1.23.0 (from ultralytics)\n",
      "  Using cached numpy-2.3.3-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Collecting matplotlib>=3.3.0 (from ultralytics)\n",
      "  Using cached matplotlib-3.10.6-cp312-cp312-win_amd64.whl.metadata (11 kB)\n",
      "Collecting opencv-python>=4.6.0 (from ultralytics)\n",
      "  Using cached opencv_python-4.12.0.88-cp37-abi3-win_amd64.whl.metadata (19 kB)\n",
      "Collecting pillow>=7.1.2 (from ultralytics)\n",
      "  Using cached pillow-11.3.0-cp312-cp312-win_amd64.whl.metadata (9.2 kB)\n",
      "Collecting pyyaml>=5.3.1 (from ultralytics)\n",
      "  Using cached PyYAML-6.0.2-cp312-cp312-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting requests>=2.23.0 (from ultralytics)\n",
      "  Using cached requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting scipy>=1.4.1 (from ultralytics)\n",
      "  Using cached scipy-1.16.2-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Collecting torch>=1.8.0 (from ultralytics)\n",
      "  Using cached torch-2.8.0-cp312-cp312-win_amd64.whl.metadata (30 kB)\n",
      "Collecting torchvision>=0.9.0 (from ultralytics)\n",
      "  Using cached torchvision-0.23.0-cp312-cp312-win_amd64.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: psutil in c:\\users\\егор\\vscode project\\avito_test_task\\venv\\lib\\site-packages (from ultralytics) (7.1.0)\n",
      "Collecting polars (from ultralytics)\n",
      "  Downloading polars-1.33.1-cp39-abi3-win_amd64.whl.metadata (15 kB)\n",
      "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
      "  Downloading ultralytics_thop-2.0.17-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib>=3.3.0->ultralytics)\n",
      "  Using cached contourpy-1.3.3-cp312-cp312-win_amd64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib>=3.3.0->ultralytics)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib>=3.3.0->ultralytics)\n",
      "  Using cached fonttools-4.60.0-cp312-cp312-win_amd64.whl.metadata (113 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib>=3.3.0->ultralytics)\n",
      "  Using cached kiwisolver-1.4.9-cp312-cp312-win_amd64.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\егор\\vscode project\\avito_test_task\\venv\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib>=3.3.0->ultralytics)\n",
      "  Using cached pyparsing-3.2.4-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\егор\\vscode project\\avito_test_task\\venv\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
      "Collecting numpy>=1.23.0 (from ultralytics)\n",
      "  Using cached numpy-2.2.6-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests>=2.23.0->ultralytics)\n",
      "  Using cached charset_normalizer-3.4.3-cp312-cp312-win_amd64.whl.metadata (37 kB)\n",
      "Collecting idna<4,>=2.5 (from requests>=2.23.0->ultralytics)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests>=2.23.0->ultralytics)\n",
      "  Using cached urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests>=2.23.0->ultralytics)\n",
      "  Using cached certifi-2025.8.3-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting filelock (from torch>=1.8.0->ultralytics)\n",
      "  Using cached filelock-3.19.1-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting typing-extensions>=4.10.0 (from torch>=1.8.0->ultralytics)\n",
      "  Using cached typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting sympy>=1.13.3 (from torch>=1.8.0->ultralytics)\n",
      "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch>=1.8.0->ultralytics)\n",
      "  Using cached networkx-3.5-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting jinja2 (from torch>=1.8.0->ultralytics)\n",
      "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting fsspec (from torch>=1.8.0->ultralytics)\n",
      "  Using cached fsspec-2025.9.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting setuptools (from torch>=1.8.0->ultralytics)\n",
      "  Using cached setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\егор\\vscode project\\avito_test_task\\venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch>=1.8.0->ultralytics)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch>=1.8.0->ultralytics)\n",
      "  Using cached MarkupSafe-3.0.2-cp312-cp312-win_amd64.whl.metadata (4.1 kB)\n",
      "Downloading ultralytics-8.3.202-py3-none-any.whl (1.1 MB)\n",
      "   ---------------------------------------- 0.0/1.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.1/1.1 MB 7.4 MB/s eta 0:00:00\n",
      "Using cached matplotlib-3.10.6-cp312-cp312-win_amd64.whl (8.1 MB)\n",
      "Using cached opencv_python-4.12.0.88-cp37-abi3-win_amd64.whl (39.0 MB)\n",
      "Using cached numpy-2.2.6-cp312-cp312-win_amd64.whl (12.6 MB)\n",
      "Using cached pillow-11.3.0-cp312-cp312-win_amd64.whl (7.0 MB)\n",
      "Using cached PyYAML-6.0.2-cp312-cp312-win_amd64.whl (156 kB)\n",
      "Using cached requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Using cached scipy-1.16.2-cp312-cp312-win_amd64.whl (38.6 MB)\n",
      "Using cached torch-2.8.0-cp312-cp312-win_amd64.whl (241.3 MB)\n",
      "Using cached torchvision-0.23.0-cp312-cp312-win_amd64.whl (1.6 MB)\n",
      "Downloading ultralytics_thop-2.0.17-py3-none-any.whl (28 kB)\n",
      "Downloading polars-1.33.1-cp39-abi3-win_amd64.whl (39.5 MB)\n",
      "   ---------------------------------------- 0.0/39.5 MB ? eta -:--:--\n",
      "   - -------------------------------------- 1.6/39.5 MB 9.3 MB/s eta 0:00:05\n",
      "   --- ------------------------------------ 3.4/39.5 MB 8.4 MB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 5.0/39.5 MB 8.4 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 6.6/39.5 MB 8.4 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 8.4/39.5 MB 8.4 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 10.2/39.5 MB 8.4 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 12.1/39.5 MB 8.4 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 13.6/39.5 MB 8.4 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 15.5/39.5 MB 8.5 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 17.3/39.5 MB 8.5 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 19.1/39.5 MB 8.6 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 21.0/39.5 MB 8.6 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 22.8/39.5 MB 8.6 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 24.6/39.5 MB 8.7 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 26.7/39.5 MB 8.7 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 28.6/39.5 MB 8.7 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 30.4/39.5 MB 8.8 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 31.7/39.5 MB 8.7 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 32.5/39.5 MB 8.6 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 33.0/39.5 MB 8.3 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 33.6/39.5 MB 7.9 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 33.8/39.5 MB 7.7 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 34.1/39.5 MB 7.4 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 34.6/39.5 MB 7.1 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 34.9/39.5 MB 7.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 35.4/39.5 MB 6.7 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 35.9/39.5 MB 6.5 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 36.2/39.5 MB 6.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 36.7/39.5 MB 6.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 37.2/39.5 MB 6.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 37.7/39.5 MB 6.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 38.3/39.5 MB 5.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.8/39.5 MB 5.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  39.3/39.5 MB 5.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 39.5/39.5 MB 5.6 MB/s eta 0:00:00\n",
      "Using cached certifi-2025.8.3-py3-none-any.whl (161 kB)\n",
      "Using cached charset_normalizer-3.4.3-cp312-cp312-win_amd64.whl (107 kB)\n",
      "Using cached contourpy-1.3.3-cp312-cp312-win_amd64.whl (226 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Using cached fonttools-4.60.0-cp312-cp312-win_amd64.whl (2.3 MB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Using cached kiwisolver-1.4.9-cp312-cp312-win_amd64.whl (73 kB)\n",
      "Using cached pyparsing-3.2.4-py3-none-any.whl (113 kB)\n",
      "Using cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "Using cached typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
      "Using cached urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Using cached filelock-3.19.1-py3-none-any.whl (15 kB)\n",
      "Using cached fsspec-2025.9.0-py3-none-any.whl (199 kB)\n",
      "Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Using cached networkx-3.5-py3-none-any.whl (2.0 MB)\n",
      "Using cached setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n",
      "Using cached MarkupSafe-3.0.2-cp312-cp312-win_amd64.whl (15 kB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Installing collected packages: mpmath, urllib3, typing-extensions, sympy, setuptools, pyyaml, pyparsing, polars, pillow, numpy, networkx, MarkupSafe, kiwisolver, idna, fsspec, fonttools, filelock, cycler, charset_normalizer, certifi, scipy, requests, opencv-python, jinja2, contourpy, torch, matplotlib, ultralytics-thop, torchvision, ultralytics\n",
      "Successfully installed MarkupSafe-3.0.2 certifi-2025.8.3 charset_normalizer-3.4.3 contourpy-1.3.3 cycler-0.12.1 filelock-3.19.1 fonttools-4.60.0 fsspec-2025.9.0 idna-3.10 jinja2-3.1.6 kiwisolver-1.4.9 matplotlib-3.10.6 mpmath-1.3.0 networkx-3.5 numpy-2.2.6 opencv-python-4.12.0.88 pillow-11.3.0 polars-1.33.1 pyparsing-3.2.4 pyyaml-6.0.2 requests-2.32.5 scipy-1.16.2 setuptools-80.9.0 sympy-1.14.0 torch-2.8.0 torchvision-0.23.0 typing-extensions-4.15.0 ultralytics-8.3.202 ultralytics-thop-2.0.17 urllib3-2.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: добавлено 5332 изображений с книгами\n",
      "val: добавлено 230 изображений с книгами\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Пути\n",
    "coco_path = \"data/coco2017\"\n",
    "combined_path = \"data/combined\"\n",
    "\n",
    "splits = {\"train2017\": \"train\", \"val2017\": \"val\"}\n",
    "\n",
    "for coco_split, yolo_split in splits.items():\n",
    "    ann_file = os.path.join(coco_path, \"annotations\", f\"instances_{coco_split}.json\")\n",
    "    with open(ann_file, \"r\") as f:\n",
    "        coco = json.load(f)\n",
    "\n",
    "    book_id = 84  # id \"book\" в COCO\n",
    "\n",
    "    # Берём только аннотации книг\n",
    "    anns_book = [ann for ann in coco[\"annotations\"] if ann[\"category_id\"] == book_id]\n",
    "\n",
    "    # Изображения с книгами\n",
    "    img_ids = set([a[\"image_id\"] for a in anns_book])\n",
    "    imgs_book = [img for img in coco[\"images\"] if img[\"id\"] in img_ids]\n",
    "\n",
    "    # Папки куда класть\n",
    "    img_save_dir = os.path.join(combined_path, \"images\", yolo_split)\n",
    "    lbl_save_dir = os.path.join(combined_path, \"labels\", yolo_split)\n",
    "    os.makedirs(img_save_dir, exist_ok=True)\n",
    "    os.makedirs(lbl_save_dir, exist_ok=True)\n",
    "\n",
    "    # Источник картинок\n",
    "    src_img_dir = os.path.join(coco_path, coco_split)\n",
    "\n",
    "    for img in imgs_book:\n",
    "        img_id = img[\"id\"]\n",
    "        w, h = img[\"width\"], img[\"height\"]\n",
    "\n",
    "        anns = [a for a in anns_book if a[\"image_id\"] == img_id]\n",
    "\n",
    "        # Чтобы не было коллизий имён\n",
    "        base_name = f\"coco_{img['file_name']}\"\n",
    "        dst_img = os.path.join(img_save_dir, base_name)\n",
    "        src_img = os.path.join(src_img_dir, img[\"file_name\"])\n",
    "        shutil.copyfile(src_img, dst_img)\n",
    "\n",
    "        # YOLO аннотации\n",
    "        lines = []\n",
    "        for a in anns:\n",
    "            x, y, bw, bh = a[\"bbox\"]\n",
    "            xc = (x + bw / 2) / w\n",
    "            yc = (y + bh / 2) / h\n",
    "            bw /= w\n",
    "            bh /= h\n",
    "            # class_id = 0 → \"book\"\n",
    "            lines.append(f\"0 {xc:.6f} {yc:.6f} {bw:.6f} {bh:.6f}\")\n",
    "\n",
    "        # txt сохраняем в labels\n",
    "        label_file = os.path.join(lbl_save_dir, base_name.replace(\".jpg\", \".txt\"))\n",
    "        with open(label_file, \"w\") as f:\n",
    "            f.write(\"\\n\".join(lines))\n",
    "\n",
    "    print(f\"{yolo_split}: добавлено {len(imgs_book)} изображений с книгами\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.202  Python-3.12.5 torch-2.8.0+cpu CPU (AMD Ryzen 5 5600H with Radeon Graphics)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=8, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=C:\\Users\\\\VsCode project\\avito_test_task\\data\\combined\\data.yaml, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo11n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train5, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=C:\\Users\\\\VsCode project\\avito_test_task\\runs\\detect\\train5, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
      "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
      " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
      " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
      " 23        [16, 19, 22]  1    430867  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
      "YOLO11n summary: 181 layers, 2,590,035 parameters, 2,590,019 gradients, 6.4 GFLOPs\n",
      "\n",
      "Transferred 448/499 items from pretrained weights\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 157.550.3 MB/s, size: 36.4 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\Егор\\VsCode project\\avito_test_task\\data\\combined\\labels\\train.cache... 4340 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 4340/4340  0.0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.1 ms, read: 125.247.8 MB/s, size: 35.1 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Егор\\VsCode project\\avito_test_task\\data\\combined\\labels\\val.cache... 858 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 858/858 849.0Kit/s 0.0s\n",
      "Plotting labels to C:\\Users\\\\VsCode project\\avito_test_task\\runs\\detect\\train5\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mC:\\Users\\\\VsCode project\\avito_test_task\\runs\\detect\\train5\u001b[0m\n",
      "Starting training for 1 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K        1/1         0G      1.091      2.607      1.491         25        640: 0% ──────────── 2/543 0.2it/s 8.3s<48:4020\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     12\u001b[39m         param.requires_grad = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# Обучение\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m results = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimgsz\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m640\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m8\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# Валидация\u001b[39;00m\n\u001b[32m     18\u001b[39m results = model.val()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Егор\\VsCode project\\avito_test_task\\venv\\Lib\\site-packages\\ultralytics\\engine\\model.py:800\u001b[39m, in \u001b[36mModel.train\u001b[39m\u001b[34m(self, trainer, **kwargs)\u001b[39m\n\u001b[32m    797\u001b[39m     \u001b[38;5;28mself\u001b[39m.trainer.model = \u001b[38;5;28mself\u001b[39m.trainer.get_model(weights=\u001b[38;5;28mself\u001b[39m.model \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.ckpt \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, cfg=\u001b[38;5;28mself\u001b[39m.model.yaml)\n\u001b[32m    798\u001b[39m     \u001b[38;5;28mself\u001b[39m.model = \u001b[38;5;28mself\u001b[39m.trainer.model\n\u001b[32m--> \u001b[39m\u001b[32m800\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    801\u001b[39m \u001b[38;5;66;03m# Update model and cfg after training\u001b[39;00m\n\u001b[32m    802\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m RANK \u001b[38;5;129;01min\u001b[39;00m {-\u001b[32m1\u001b[39m, \u001b[32m0\u001b[39m}:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Егор\\VsCode project\\avito_test_task\\venv\\Lib\\site-packages\\ultralytics\\engine\\trainer.py:235\u001b[39m, in \u001b[36mBaseTrainer.train\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    232\u001b[39m         ddp_cleanup(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mstr\u001b[39m(file))\n\u001b[32m    234\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m235\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_do_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Егор\\VsCode project\\avito_test_task\\venv\\Lib\\site-packages\\ultralytics\\engine\\trainer.py:433\u001b[39m, in \u001b[36mBaseTrainer._do_train\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    431\u001b[39m \u001b[38;5;66;03m# Optimize - https://pytorch.org/docs/master/notes/amp_examples.html\u001b[39;00m\n\u001b[32m    432\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ni - last_opt_step >= \u001b[38;5;28mself\u001b[39m.accumulate:\n\u001b[32m--> \u001b[39m\u001b[32m433\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    434\u001b[39m     last_opt_step = ni\n\u001b[32m    436\u001b[39m     \u001b[38;5;66;03m# Timed stopping\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Егор\\VsCode project\\avito_test_task\\venv\\Lib\\site-packages\\ultralytics\\engine\\trainer.py:669\u001b[39m, in \u001b[36mBaseTrainer.optimizer_step\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    667\u001b[39m \u001b[38;5;28mself\u001b[39m.scaler.unscale_(\u001b[38;5;28mself\u001b[39m.optimizer)  \u001b[38;5;66;03m# unscale gradients\u001b[39;00m\n\u001b[32m    668\u001b[39m torch.nn.utils.clip_grad_norm_(\u001b[38;5;28mself\u001b[39m.model.parameters(), max_norm=\u001b[32m10.0\u001b[39m)  \u001b[38;5;66;03m# clip gradients\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m669\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mscaler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    670\u001b[39m \u001b[38;5;28mself\u001b[39m.scaler.update()\n\u001b[32m    671\u001b[39m \u001b[38;5;28mself\u001b[39m.optimizer.zero_grad()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Егор\\VsCode project\\avito_test_task\\venv\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:388\u001b[39m, in \u001b[36mGradScaler.step\u001b[39m\u001b[34m(self, optimizer, *args, **kwargs)\u001b[39m\n\u001b[32m    366\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Invoke ``unscale_(optimizer)`` followed by parameter update, if gradients are not infs/NaN.\u001b[39;00m\n\u001b[32m    367\u001b[39m \n\u001b[32m    368\u001b[39m \u001b[33;03m:meth:`step` carries out the following two operations:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    385\u001b[39m \u001b[33;03m    Closure use is not currently supported.\u001b[39;00m\n\u001b[32m    386\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    387\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._enabled:\n\u001b[32m--> \u001b[39m\u001b[32m388\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    390\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mclosure\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[32m    391\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    392\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mClosure use is not currently supported if GradScaler is enabled.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    393\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Егор\\VsCode project\\avito_test_task\\venv\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:133\u001b[39m, in \u001b[36mLRScheduler.__init__.<locals>.patch_track_step_called.<locals>.wrap_step.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    131\u001b[39m opt = opt_ref()\n\u001b[32m    132\u001b[39m opt._opt_called = \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m133\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__get__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__class__\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Егор\\VsCode project\\avito_test_task\\venv\\Lib\\site-packages\\torch\\optim\\optimizer.py:516\u001b[39m, in \u001b[36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    511\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    512\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    513\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    514\u001b[39m             )\n\u001b[32m--> \u001b[39m\u001b[32m516\u001b[39m out = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    517\u001b[39m \u001b[38;5;28mself\u001b[39m._optimizer_step_code()\n\u001b[32m    519\u001b[39m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Егор\\VsCode project\\avito_test_task\\venv\\Lib\\site-packages\\torch\\optim\\optimizer.py:81\u001b[39m, in \u001b[36m_use_grad_for_differentiable.<locals>._use_grad\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     79\u001b[39m     torch.set_grad_enabled(\u001b[38;5;28mself\u001b[39m.defaults[\u001b[33m\"\u001b[39m\u001b[33mdifferentiable\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     80\u001b[39m     torch._dynamo.graph_break()\n\u001b[32m---> \u001b[39m\u001b[32m81\u001b[39m     ret = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     82\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     83\u001b[39m     torch._dynamo.graph_break()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Егор\\VsCode project\\avito_test_task\\venv\\Lib\\site-packages\\torch\\optim\\adam.py:247\u001b[39m, in \u001b[36mAdam.step\u001b[39m\u001b[34m(self, closure)\u001b[39m\n\u001b[32m    235\u001b[39m     beta1, beta2 = group[\u001b[33m\"\u001b[39m\u001b[33mbetas\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    237\u001b[39m     has_complex = \u001b[38;5;28mself\u001b[39m._init_group(\n\u001b[32m    238\u001b[39m         group,\n\u001b[32m    239\u001b[39m         params_with_grad,\n\u001b[32m   (...)\u001b[39m\u001b[32m    244\u001b[39m         state_steps,\n\u001b[32m    245\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m247\u001b[39m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    248\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    249\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    250\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mamsgrad\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    256\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    257\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    258\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    259\u001b[39m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweight_decay\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    260\u001b[39m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43meps\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    261\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmaximize\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    262\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mforeach\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    263\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcapturable\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    264\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdifferentiable\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    265\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfused\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    266\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgrad_scale\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    267\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfound_inf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    268\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdecoupled_weight_decay\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    269\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    271\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Егор\\VsCode project\\avito_test_task\\venv\\Lib\\site-packages\\torch\\optim\\optimizer.py:149\u001b[39m, in \u001b[36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    147\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m disabled_func(*args, **kwargs)\n\u001b[32m    148\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m149\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Егор\\VsCode project\\avito_test_task\\venv\\Lib\\site-packages\\torch\\optim\\adam.py:949\u001b[39m, in \u001b[36madam\u001b[39m\u001b[34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, decoupled_weight_decay, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[39m\n\u001b[32m    946\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    947\u001b[39m     func = _single_tensor_adam\n\u001b[32m--> \u001b[39m\u001b[32m949\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    950\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    951\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    952\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    953\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    954\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    955\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    956\u001b[39m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    957\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    958\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    959\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    960\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    961\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    962\u001b[39m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[43m=\u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    963\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    964\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    965\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    966\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    967\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    968\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    969\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Егор\\VsCode project\\avito_test_task\\venv\\Lib\\site-packages\\torch\\optim\\adam.py:533\u001b[39m, in \u001b[36m_single_tensor_adam\u001b[39m\u001b[34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable, decoupled_weight_decay)\u001b[39m\n\u001b[32m    531\u001b[39m         denom = (max_exp_avg_sqs[i].sqrt() / bias_correction2_sqrt).add_(eps)\n\u001b[32m    532\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m533\u001b[39m         denom = \u001b[43m(\u001b[49m\u001b[43mexp_avg_sq\u001b[49m\u001b[43m.\u001b[49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias_correction2_sqrt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43madd_\u001b[49m\u001b[43m(\u001b[49m\u001b[43meps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    535\u001b[39m     param.addcdiv_(exp_avg, denom, value=-step_size)\n\u001b[32m    537\u001b[39m \u001b[38;5;66;03m# Lastly, switch back to complex view\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Загружаем предобученную модель\n",
    "model = YOLO(\"yolo11n.pt\")\n",
    "\n",
    "# Путь к data.yaml объединённого датасета\n",
    "data_path = r\"C:\\Users\\Егор\\VsCode project\\avito_test_task\\data\\combined\\data.yaml\"\n",
    "\n",
    "# Заморозим backbone (опционально)\n",
    "for name, param in model.model.named_parameters():\n",
    "    if \"backbone\" in name:\n",
    "        param.requires_grad = False\n",
    "\n",
    "# Обучение\n",
    "results = model.train(data=data_path, epochs=1, imgsz=640, batch=8)\n",
    "\n",
    "# Валидация\n",
    "results = model.val()\n",
    "\n",
    "# Инференс на тестовой картинке\n",
    "img_path = r\"C:\\Users\\Егор\\VsCode project\\avito_test_task\\data\\all-books\\test\\images\\7b28dc3d5e10a9bf_jpg.rf.9e67de51e48f9806fa7b0d0e39cae7da.jpg\"\n",
    "results = model(img_path)\n",
    "results[0].show()\n",
    "\n",
    "# Экспорт в ONNX\n",
    "success = model.export(format=\"onnx\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
